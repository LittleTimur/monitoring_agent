# Анализ первых трех пунктов ТЗ 3 этапа

## Пункт 1: Создание сервера с бэком для обработки данных

### Что нужно сделать:
- Расширить функциональность сервера для управления агентами
- Добавить REST API для настройки частоты обновления данных
- Реализовать возможность включения/отключения отдельных метрик
- Добавить запросы к агенту по требованию
- Интегрировать сбор данных от сетевых устройств по SNMP протоколу и syslog

### Изменения в агенте:
- Добавить HTTP сервер агента для получения команд от сервера
- Реализовать структуру конфигурации для динамического изменения параметров
- Добавить API endpoints: GET/POST /config, POST /execute_script, GET /health
- Модифицировать основной цикл для использования настраиваемой частоты сбора
- Добавить фильтрацию метрик согласно конфигурации

### Изменения в сервере:
- Расширить HTTP API сервера для управления агентами
- Добавить endpoints: GET /api/agents, GET/POST /api/agents/{id}/config
- Реализовать POST /api/agents/{id}/execute_script для выполнения скриптов
- Добавить GET /api/snmp/{device_ip} для сбора SNMP данных
- Интегрировать snmpwalk/snmpget для работы с сетевыми устройствами
- Добавить обработку syslog сообщений

### Время выполнения: 2 недели
- Агент (1 неделя): HTTP сервер, конфигурация, API
- Сервер (1 недели): REST API, SNMP интеграция, обработка команд

---

## Пункт 2: Создание БД PostgreSQL для записи данных

### Что нужно сделать:
- Настроить PostgreSQL сервер и создать схему БД
- Создать таблицы для метрик, агентов, кастомных скриптов, SNMP устройств
- Реализовать сохранение всех данных от агентов в БД
- Добавить индексы для быстрого поиска и оптимизации запросов
- Настроить автоматическую очистку старых данных
- Создать функции экспорта и анализа данных

### Изменения в агенте:
- Не требуются изменения в агенте для этого пункта

### Изменения в сервере:
- Установить и настроить PostgreSQL
- Создать схему БД с таблицами: metrics, agents, custom_scripts, snmp_devices (примерно, пока точно схемы нет)
- Добавить функции для работы с БД: сохранение метрик, получение статистики
- Реализовать connection pooling для эффективной работы с БД
- Добавить миграции БД для версионирования схемы
- Настроить автоматические бэкапы и мониторинг БД
- Создать API endpoints для получения данных из БД

### Время выполнения: 2 недели
- Настройка PostgreSQL (2 дня)
- Создание схемы БД (3-4 дня)
- Индексы и оптимизация (2-3 дня)
- Интеграция с Python (2 дня)
- Функции для работы с БД (3-4 дня)
- Тестирование и отладка (3-4 дня)

---

## Пункт 3: Организовать возможность использования кастомных скриптов через агента

### Что нужно сделать:
- Реализовать безопасное выполнение пользовательских скриптов на агентах
- Добавить API для загрузки и управления скриптами
- Создать систему планирования выполнения скриптов
- Реализовать сбор и хранение результатов выполнения скриптов
- Добавить валидацию и ограничения для безопасности

### Изменения в агенте:
- Добавить безопасное выполнение скриптов с ограничениями ресурсов
- Реализовать API для загрузки и выполнения скриптов
- Добавить изоляцию выполнения скриптов
- Создать систему ограничений: время выполнения, CPU, память
- Добавить поддержку различных типов скриптов: Bash, PowerShell, Python
- Реализовать возврат результатов выполнения скриптов

### Изменения в сервере:
- Создать API для управления скриптами: загрузка, редактирование, удаление
- Реализовать планировщик выполнения скриптов
- Добавить хранение скриптов и результатов в БД
- Создать систему валидации скриптов для безопасности
- Добавить логирование выполнения скриптов
- Реализовать мониторинг выполнения скриптов

### Время выполнения: 1 неделя

---

## Общая оценка времени: 5 недель

### Детализация по неделям:
- Неделя 1-2: Пункт 1 (Сервер с бэком)
- Неделя 3-4: Пункт 2 (PostgreSQL БД)
- Неделя 5: Пункт 3 (Кастомные скрипты)

### Критические зависимости:
1. Выбор и настройка PostgreSQL
2. Требования к безопасности выполнения скриптов
3. Сложность SNMP интеграции
4. Количество тестируемых сценариев

### Рекомендации:
1. Начать с простой схемы БД и расширять по мере необходимости
2. Использовать connection pooling для эффективности работы с PostgreSQL
3. Регулярно мониторить производительность запросов
4. Настроить автоматические бэкапы с самого начала
5. Документировать все миграции БД
6. Поэтапное тестирование каждого компонента 